{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24b1c830-7b36-4f15-b2d5-402a25f5ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff821a0a-481e-4c93-bc33-775cdfde230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"lakshaymiddha/crack-segmentation-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0e2e3e-488a-46a6-a73e-71fa4ddff1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef4c84ef-6694-45cd-87e1-271fce62ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.transform = v2.Compose([\n",
    "            v2.Resize(384),\n",
    "            v2.PILToTensor(),\n",
    "            v2.ToDtype(torch.float32, scale=True)\n",
    "        ])\n",
    "        \n",
    "        self.images = [Image.open(path).convert(\"RGB\") for path in tqdm(paths)]\n",
    "        \n",
    "        self.target = []\n",
    "        for filename in files:\n",
    "            if filename.lower().startswith(\"noncrack\"):\n",
    "                self.target.append(0)\n",
    "            else:\n",
    "                self.target.append(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.transform(self.images[idx]), self.target[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34deb321-c83f-46ca-9203-6150790fba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6152252-665b-447a-9af9-1edee665b742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54227164-37a7-49d6-9d1e-ffcdc8fc08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(1280, 2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9f148a-3abd-477d-8845-f01495253563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "EfficientNet                                            [16, 2]                   --\n",
       "├─Sequential: 1-1                                       [16, 1280, 12, 12]        --\n",
       "│    └─Conv2dNormActivation: 2-1                        [16, 24, 192, 192]        --\n",
       "│    │    └─Conv2d: 3-1                                 [16, 24, 192, 192]        (648)\n",
       "│    │    └─BatchNorm2d: 3-2                            [16, 24, 192, 192]        (48)\n",
       "│    │    └─SiLU: 3-3                                   [16, 24, 192, 192]        --\n",
       "│    └─Sequential: 2-2                                  [16, 24, 192, 192]        --\n",
       "│    │    └─FusedMBConv: 3-4                            [16, 24, 192, 192]        (5,232)\n",
       "│    │    └─FusedMBConv: 3-5                            [16, 24, 192, 192]        (5,232)\n",
       "│    └─Sequential: 2-3                                  [16, 48, 96, 96]          --\n",
       "│    │    └─FusedMBConv: 3-6                            [16, 48, 96, 96]          (25,632)\n",
       "│    │    └─FusedMBConv: 3-7                            [16, 48, 96, 96]          (92,640)\n",
       "│    │    └─FusedMBConv: 3-8                            [16, 48, 96, 96]          (92,640)\n",
       "│    │    └─FusedMBConv: 3-9                            [16, 48, 96, 96]          (92,640)\n",
       "│    └─Sequential: 2-4                                  [16, 64, 48, 48]          --\n",
       "│    │    └─FusedMBConv: 3-10                           [16, 64, 48, 48]          (95,744)\n",
       "│    │    └─FusedMBConv: 3-11                           [16, 64, 48, 48]          (164,480)\n",
       "│    │    └─FusedMBConv: 3-12                           [16, 64, 48, 48]          (164,480)\n",
       "│    │    └─FusedMBConv: 3-13                           [16, 64, 48, 48]          (164,480)\n",
       "│    └─Sequential: 2-5                                  [16, 128, 24, 24]         --\n",
       "│    │    └─MBConv: 3-14                                [16, 128, 24, 24]         (61,200)\n",
       "│    │    └─MBConv: 3-15                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-16                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-17                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-18                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-19                                [16, 128, 24, 24]         (171,296)\n",
       "│    └─Sequential: 2-6                                  [16, 160, 24, 24]         --\n",
       "│    │    └─MBConv: 3-20                                [16, 160, 24, 24]         (281,440)\n",
       "│    │    └─MBConv: 3-21                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-22                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-23                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-24                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-25                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-26                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-27                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-28                                [16, 160, 24, 24]         (397,800)\n",
       "│    └─Sequential: 2-7                                  [16, 256, 12, 12]         --\n",
       "│    │    └─MBConv: 3-29                                [16, 256, 12, 12]         (490,152)\n",
       "│    │    └─MBConv: 3-30                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-31                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-32                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-33                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-34                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-35                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-36                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-37                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-38                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-39                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-40                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-41                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-42                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-43                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    └─Conv2dNormActivation: 2-8                        [16, 1280, 12, 12]        --\n",
       "│    │    └─Conv2d: 3-44                                [16, 1280, 12, 12]        (327,680)\n",
       "│    │    └─BatchNorm2d: 3-45                           [16, 1280, 12, 12]        (2,560)\n",
       "│    │    └─SiLU: 3-46                                  [16, 1280, 12, 12]        --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [16, 1280, 1, 1]          --\n",
       "├─Sequential: 1-3                                       [16, 2]                   --\n",
       "│    └─Dropout: 2-9                                     [16, 1280]                --\n",
       "│    └─Linear: 2-10                                     [16, 2]                   2,562\n",
       "=========================================================================================================\n",
       "Total params: 20,180,050\n",
       "Trainable params: 2,562\n",
       "Non-trainable params: 20,177,488\n",
       "Total mult-adds (Units.GIGABYTES): 133.83\n",
       "=========================================================================================================\n",
       "Input size (MB): 28.31\n",
       "Forward/backward pass size (MB): 9151.50\n",
       "Params size (MB): 80.72\n",
       "Estimated Total Size (MB): 9260.53\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(16, 3, 384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "644aea0d-48fc-49f9-b3aa-db10c56f9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, optimizer, scheduler, loss_fn, scaler, device):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "\n",
    "    for batch, target in dataloader:\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast('cuda'):\n",
    "            logits = model(batch)\n",
    "            loss = loss_fn(logits.squeeze(), target.float())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Convert logits to binary predictions\n",
    "        preds = torch.sigmoid(logits)\n",
    "        preds = (preds > 0.5).int()\n",
    "\n",
    "        correct += (preds == target).sum().item()\n",
    "        total += target.numel()\n",
    "\n",
    "        # Calculate precision/recall components\n",
    "        true_pos += ((preds == 1) & (target == 1)).sum().item()\n",
    "        false_pos += ((preds == 1) & (target == 0)).sum().item()\n",
    "        false_neg += ((preds == 0) & (target == 1)).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = true_pos / (true_pos + false_pos + 1e-8)\n",
    "    recall = true_pos / (true_pos + false_neg + 1e-8)\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall\n",
    "\n",
    "def valid_step(model, dataloader, loss_fn, device):\n",
    "    avg_loss = 0\n",
    "    avg_accuracy = 0\n",
    "    avg_precision = 0\n",
    "    avg_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, target in dataloader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            logits = model(batch)\n",
    "            loss = loss_fn(logits.squeeze(), target.float())\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            preds = (preds > 0.5).int()\n",
    "\n",
    "            correct = (preds == target).sum().item()\n",
    "            total = target.numel()\n",
    "\n",
    "            true_pos = ((preds == 1) & (target == 1)).sum().item()\n",
    "            false_pos = ((preds == 1) & (target == 0)).sum().item()\n",
    "            false_neg = ((preds == 0) & (target == 1)).sum().item()\n",
    "\n",
    "            accuracy = correct / total\n",
    "            precision = true_pos / (true_pos + false_pos + 1e-8)\n",
    "            recall = true_pos / (true_pos + false_neg + 1e-8)\n",
    "\n",
    "            avg_accuracy += accuracy\n",
    "            avg_precision += precision\n",
    "            avg_recall += recall\n",
    "\n",
    "    avg_loss /= len(dataloader)\n",
    "    avg_accuracy /= len(dataloader)\n",
    "    avg_precision /= len(dataloader)\n",
    "    avg_recall /= len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_accuracy, avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aea5de59-829a-40c9-8a24-4092da0a15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, optimizer, scheduler: OneCycleLR, loss_fn, epochs, start_checkpoint=None):\n",
    "    os.makedirs('../tmp_model_checkpoints', exist_ok=True)\n",
    "    counter = 0 # count epochs without printing training stats\n",
    "    scaler = GradScaler('cuda')\n",
    "    \n",
    "    if start_checkpoint:\n",
    "        start_epoch = start_checkpoint['epoch'] + 1\n",
    "        best_acc = start_checkpoint['best_acc']\n",
    "        best_prec = start_checkpoint['best_prec']\n",
    "        best_rec = start_checkpoint['best_rec']\n",
    "        scaler.load_state_dict(start_checkpoint['scaler_state_dict'])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_acc = 0\n",
    "        best_prec = 0\n",
    "        best_rec = 0\n",
    "        \n",
    "    log_freq = (epochs - start_epoch) // 10 # how often to print stats when no progress is made\n",
    "    \n",
    "    for epoch in tqdm(range(start_epoch, epochs), desc=\"Epochs\"):\n",
    "        counter += 1\n",
    "        train_loss, train_acc, train_prec, train_rec = train_step(\n",
    "            model,\n",
    "            train_dl,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            loss_fn,\n",
    "            scaler,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        valid_loss, valid_acc, valid_prec, valid_rec = valid_step(\n",
    "            model,\n",
    "            valid_dl,\n",
    "            loss_fn,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        progress = False\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            progress = True\n",
    "            best_acc = valid_acc\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_accuracy.pth')\n",
    "\n",
    "        if valid_prec > best_prec:\n",
    "            progress = True\n",
    "            best_prec = valid_prec\n",
    "            ccheckpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_precision.pth')\n",
    "\n",
    "        if valid_recc < best_recc:\n",
    "            progress = True\n",
    "            best_recc = valid_recc\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_recall.pth')\n",
    "\n",
    "        if epoch == epochs-1:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/last.pth')\n",
    "            \n",
    "        if progress or counter >= log_freq:\n",
    "            counter = 0\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"learning rate: {scheduler.get_last_lr()[0]:.6f} | \"\n",
    "                f\"[train] loss: {train_loss:.4f} | \"\n",
    "                f\"[valid] loss: {valid_loss:.4f} | \"\n",
    "                f\"[valid] Accuracy: {valid_acc:.4f} | \"\n",
    "                f\"[valid] Precision: {valid_prec:.4f} | \"\n",
    "                f\"[valid] Recall: {valid_rec:.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dbe29c3-3879-4169-8db1-732dd406316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"train/images/\")\n",
    "paths = [os.path.join(\"train/images/\", filename) for filename in files if filename.lower().endswith(\".jpg\")]\n",
    "random.shuffle(paths)\n",
    "split_idx = int(0.8 * len(paths))\n",
    "train_paths = paths[:split_idx]\n",
    "valid_paths = paths[split_idx:]\n",
    "\n",
    "files = os.listdir(\"test/images/\")\n",
    "test_paths = [os.path.join(\"test/images/\", filename) for filename in files if filename.lower().endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7292c6f6-8fe3-45a0-b722-c851e34fbae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b866b40dae44f9788befdf464b49e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7682 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8777c1b79964d6bb69017ebf3341fb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614d50e8be9c44c0b1209ddf7ad9406e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = CrackDataset(train_paths)\n",
    "valid_ds = CrackDataset(valid_paths)\n",
    "test_ds = CrackDataset(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e004c07f-7e9d-473b-b530-42dea13569c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fz/jnkjfhxj2vzb31m0gzs0xzvw0000gn/T/ipykernel_59866/3069466459.py:4: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  scaler = GradScaler('cuda')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4a47c756c464840be82a4ba0e36187e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m optimizer = Adam(model.parameters(), lr=\u001b[32m1e-2\u001b[39m)\n\u001b[32m      6\u001b[39m scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=\u001b[32m0.1\u001b[39m, steps_per_epoch=\u001b[38;5;28mlen\u001b[39m(train_dl), epochs=\u001b[32m1000\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_dl, valid_dl, optimizer, scheduler, loss_fn, epochs, start_checkpoint)\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(start_epoch, epochs), desc=\u001b[33m\"\u001b[39m\u001b[33mEpochs\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     21\u001b[39m     counter += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     train_loss, train_acc, train_prec, train_rec = \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m     valid_loss, valid_acc, valid_prec, valid_rec = valid_step(\n\u001b[32m     33\u001b[39m         model,\n\u001b[32m     34\u001b[39m         valid_dl,\n\u001b[32m     35\u001b[39m         loss_fn,\n\u001b[32m     36\u001b[39m         device\n\u001b[32m     37\u001b[39m     )\n\u001b[32m     39\u001b[39m     progress = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mtrain_step\u001b[39m\u001b[34m(model, dataloader, optimizer, scheduler, loss_fn, scaler, device)\u001b[39m\n\u001b[32m      8\u001b[39m false_pos = \u001b[32m0\u001b[39m\n\u001b[32m      9\u001b[39m false_neg = \u001b[32m0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sem5/DL/labs/DL_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:494\u001b[39m, in \u001b[36mDataLoader.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iterator\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sem5/DL/labs/DL_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:427\u001b[39m, in \u001b[36mDataLoader._get_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    425\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    426\u001b[39m     \u001b[38;5;28mself\u001b[39m.check_worker_number_rationality()\n\u001b[32m--> \u001b[39m\u001b[32m427\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sem5/DL/labs/DL_venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1170\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter.__init__\u001b[39m\u001b[34m(self, loader)\u001b[39m\n\u001b[32m   1163\u001b[39m w.daemon = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1164\u001b[39m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[32m   1165\u001b[39m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[32m   1166\u001b[39m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[32m   1167\u001b[39m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[32m   1168\u001b[39m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[32m   1169\u001b[39m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1170\u001b[39m \u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28mself\u001b[39m._index_queues.append(index_queue)\n\u001b[32m   1172\u001b[39m \u001b[38;5;28mself\u001b[39m._workers.append(w)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py:19\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:47\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     46\u001b[39m     reduction.dump(prep_data, fp)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     \u001b[43mreduction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     49\u001b[39m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/reduction.py:60\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdump\u001b[39m(obj, file, protocol=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     59\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sem5/DL/labs/DL_venv/lib/python3.12/site-packages/PIL/Image.py:750\u001b[39m, in \u001b[36mImage.__getstate__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    749\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getstate__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[Any]:\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m     im_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# load image first\u001b[39;00m\n\u001b[32m    751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m.info, \u001b[38;5;28mself\u001b[39m.mode, \u001b[38;5;28mself\u001b[39m.size, \u001b[38;5;28mself\u001b[39m.getpalette(), im_data]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/sem5/DL/labs/DL_venv/lib/python3.12/site-packages/PIL/Image.py:811\u001b[39m, in \u001b[36mImage.tobytes\u001b[39m\u001b[34m(self, encoder_name, *args)\u001b[39m\n\u001b[32m    809\u001b[39m output = []\n\u001b[32m    810\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m     bytes_consumed, errcode, data = \u001b[43me\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbufsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    812\u001b[39m     output.append(data)\n\u001b[32m    813\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errcode:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=os.cpu_count()-1)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=16, shuffle=False, num_workers=os.cpu_count()-1)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_dl), epochs=1000)\n",
    "\n",
    "train(model, train_dl, valid_dl, optimizer, scheduler, loss_fn, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ce07c-31b1-4475-a3cb-23be5acdc6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_venv",
   "language": "python",
   "name": "dl_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
