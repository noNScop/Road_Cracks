{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b1c830-7b36-4f15-b2d5-402a25f5ad85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from torch.optim import Adam\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import v2\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import efficientnet_v2_s, EfficientNet_V2_S_Weights, resnet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff821a0a-481e-4c93-bc33-775cdfde230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kagglehub\n",
    "\n",
    "# # Download latest version\n",
    "# path = kagglehub.dataset_download(\"lakshaymiddha/crack-segmentation-dataset\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c0e2e3e-488a-46a6-a73e-71fa4ddff1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef4c84ef-6694-45cd-87e1-271fce62ffeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrackDataset(Dataset):\n",
    "    def __init__(self, paths):\n",
    "        self.transform = v2.Compose([\n",
    "            v2.Resize(384), # Use 384 for EfficientNet, whatever for resnet\n",
    "            v2.PILToTensor(),\n",
    "            v2.ToDtype(torch.float32, scale=True)\n",
    "        ])\n",
    "        \n",
    "        self.images = [Image.open(path).convert(\"RGB\") for path in tqdm(paths)]\n",
    "        \n",
    "        self.targets = []\n",
    "        for filename in paths:\n",
    "            if filename.lower().startswith(\"noncrack\"):\n",
    "                self.targets.append(0)\n",
    "            else:\n",
    "                self.targets.append(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.transform(self.images[idx])\n",
    "        target = torch.tensor(self.targets[idx], dtype=torch.float32)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d046a42-5bb5-4adb-b039-7a40a65f062a",
   "metadata": {},
   "source": [
    "## EfficientNet_V2_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34deb321-c83f-46ca-9203-6150790fba2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = efficientnet_v2_s(weights=EfficientNet_V2_S_Weights.DEFAULT)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6152252-665b-447a-9af9-1edee665b742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Dropout(p=0.2, inplace=True)\n",
       "  (1): Linear(in_features=1280, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54227164-37a7-49d6-9d1e-ffcdc8fc08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(1280, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb12cdce-7845-4484-8899-7350ad8762e6",
   "metadata": {},
   "source": [
    "## ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80d2996f-1b11-4cef-a082-350f0896621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = resnet18()\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac137f6a-f351-4761-b868-f5b117c0ae97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fc = nn.Linear(512, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fe32cd-bdc0-43a8-897a-c0552488a09d",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4fa29c-b41c-464f-b1d2-912a03b7ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9f148a-3abd-477d-8845-f01495253563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "EfficientNet                                            [16, 1]                   --\n",
       "├─Sequential: 1-1                                       [16, 1280, 12, 12]        --\n",
       "│    └─Conv2dNormActivation: 2-1                        [16, 24, 192, 192]        --\n",
       "│    │    └─Conv2d: 3-1                                 [16, 24, 192, 192]        (648)\n",
       "│    │    └─BatchNorm2d: 3-2                            [16, 24, 192, 192]        (48)\n",
       "│    │    └─SiLU: 3-3                                   [16, 24, 192, 192]        --\n",
       "│    └─Sequential: 2-2                                  [16, 24, 192, 192]        --\n",
       "│    │    └─FusedMBConv: 3-4                            [16, 24, 192, 192]        (5,232)\n",
       "│    │    └─FusedMBConv: 3-5                            [16, 24, 192, 192]        (5,232)\n",
       "│    └─Sequential: 2-3                                  [16, 48, 96, 96]          --\n",
       "│    │    └─FusedMBConv: 3-6                            [16, 48, 96, 96]          (25,632)\n",
       "│    │    └─FusedMBConv: 3-7                            [16, 48, 96, 96]          (92,640)\n",
       "│    │    └─FusedMBConv: 3-8                            [16, 48, 96, 96]          (92,640)\n",
       "│    │    └─FusedMBConv: 3-9                            [16, 48, 96, 96]          (92,640)\n",
       "│    └─Sequential: 2-4                                  [16, 64, 48, 48]          --\n",
       "│    │    └─FusedMBConv: 3-10                           [16, 64, 48, 48]          (95,744)\n",
       "│    │    └─FusedMBConv: 3-11                           [16, 64, 48, 48]          (164,480)\n",
       "│    │    └─FusedMBConv: 3-12                           [16, 64, 48, 48]          (164,480)\n",
       "│    │    └─FusedMBConv: 3-13                           [16, 64, 48, 48]          (164,480)\n",
       "│    └─Sequential: 2-5                                  [16, 128, 24, 24]         --\n",
       "│    │    └─MBConv: 3-14                                [16, 128, 24, 24]         (61,200)\n",
       "│    │    └─MBConv: 3-15                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-16                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-17                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-18                                [16, 128, 24, 24]         (171,296)\n",
       "│    │    └─MBConv: 3-19                                [16, 128, 24, 24]         (171,296)\n",
       "│    └─Sequential: 2-6                                  [16, 160, 24, 24]         --\n",
       "│    │    └─MBConv: 3-20                                [16, 160, 24, 24]         (281,440)\n",
       "│    │    └─MBConv: 3-21                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-22                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-23                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-24                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-25                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-26                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-27                                [16, 160, 24, 24]         (397,800)\n",
       "│    │    └─MBConv: 3-28                                [16, 160, 24, 24]         (397,800)\n",
       "│    └─Sequential: 2-7                                  [16, 256, 12, 12]         --\n",
       "│    │    └─MBConv: 3-29                                [16, 256, 12, 12]         (490,152)\n",
       "│    │    └─MBConv: 3-30                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-31                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-32                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-33                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-34                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-35                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-36                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-37                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-38                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-39                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-40                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-41                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-42                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    │    └─MBConv: 3-43                                [16, 256, 12, 12]         (1,005,120)\n",
       "│    └─Conv2dNormActivation: 2-8                        [16, 1280, 12, 12]        --\n",
       "│    │    └─Conv2d: 3-44                                [16, 1280, 12, 12]        (327,680)\n",
       "│    │    └─BatchNorm2d: 3-45                           [16, 1280, 12, 12]        (2,560)\n",
       "│    │    └─SiLU: 3-46                                  [16, 1280, 12, 12]        --\n",
       "├─AdaptiveAvgPool2d: 1-2                                [16, 1280, 1, 1]          --\n",
       "├─Sequential: 1-3                                       [16, 1]                   --\n",
       "│    └─Dropout: 2-9                                     [16, 1280]                --\n",
       "│    └─Linear: 2-10                                     [16, 1]                   1,281\n",
       "=========================================================================================================\n",
       "Total params: 20,178,769\n",
       "Trainable params: 1,281\n",
       "Non-trainable params: 20,177,488\n",
       "Total mult-adds (Units.GIGABYTES): 133.83\n",
       "=========================================================================================================\n",
       "Input size (MB): 28.31\n",
       "Forward/backward pass size (MB): 9151.50\n",
       "Params size (MB): 80.72\n",
       "Estimated Total Size (MB): 9260.52\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(16, 3, 384, 384))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "644aea0d-48fc-49f9-b3aa-db10c56f9f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, dataloader, optimizer, scheduler, loss_fn, scaler, device):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "\n",
    "    for batch, target in dataloader:\n",
    "        batch, target = batch.to(device), target.to(device)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        with autocast('cuda'):\n",
    "            logits = model(batch)\n",
    "            loss = loss_fn(logits.squeeze(), target.squeeze())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Convert logits to binary predictions\n",
    "        preds = torch.sigmoid(logits)\n",
    "        preds = (preds > 0.5).int()\n",
    "\n",
    "        correct += (preds == target).sum().item()\n",
    "        total += target.numel()\n",
    "\n",
    "        # Calculate precision/recall components\n",
    "        true_pos += ((preds == 1) & (target == 1)).sum().item()\n",
    "        false_pos += ((preds == 1) & (target == 0)).sum().item()\n",
    "        false_neg += ((preds == 0) & (target == 1)).sum().item()\n",
    "\n",
    "    accuracy = correct / total\n",
    "    precision = true_pos / (true_pos + false_pos + 1e-8)\n",
    "    recall = true_pos / (true_pos + false_neg + 1e-8)\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "\n",
    "    return avg_loss, accuracy, precision, recall\n",
    "\n",
    "def valid_step(model, dataloader, loss_fn, device):\n",
    "    avg_loss = 0\n",
    "    avg_accuracy = 0\n",
    "    avg_precision = 0\n",
    "    avg_recall = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch, target in dataloader:\n",
    "            batch, target = batch.to(device), target.to(device)\n",
    "\n",
    "            logits = model(batch)\n",
    "            loss = loss_fn(logits.squeeze(), target.squeeze())\n",
    "            avg_loss += loss.item()\n",
    "\n",
    "            preds = torch.sigmoid(logits)\n",
    "            preds = (preds > 0.5).int()\n",
    "\n",
    "            correct = (preds == target).sum().item()\n",
    "            total = target.numel()\n",
    "\n",
    "            true_pos = ((preds == 1) & (target == 1)).sum().item()\n",
    "            false_pos = ((preds == 1) & (target == 0)).sum().item()\n",
    "            false_neg = ((preds == 0) & (target == 1)).sum().item()\n",
    "\n",
    "            accuracy = correct / total\n",
    "            precision = true_pos / (true_pos + false_pos + 1e-8)\n",
    "            recall = true_pos / (true_pos + false_neg + 1e-8)\n",
    "\n",
    "            avg_accuracy += accuracy\n",
    "            avg_precision += precision\n",
    "            avg_recall += recall\n",
    "\n",
    "    avg_loss /= len(dataloader)\n",
    "    avg_accuracy /= len(dataloader)\n",
    "    avg_precision /= len(dataloader)\n",
    "    avg_recall /= len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_accuracy, avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea5de59-829a-40c9-8a24-4092da0a15ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, optimizer, scheduler: OneCycleLR, loss_fn, epochs, start_checkpoint=None):\n",
    "    os.makedirs('../tmp_model_checkpoints', exist_ok=True)\n",
    "    counter = 0 # count epochs without printing training stats\n",
    "    scaler = GradScaler('cuda')\n",
    "    \n",
    "    if start_checkpoint:\n",
    "        start_epoch = start_checkpoint['epoch'] + 1\n",
    "        best_acc = start_checkpoint['best_acc']\n",
    "        best_prec = start_checkpoint['best_prec']\n",
    "        best_rec = start_checkpoint['best_rec']\n",
    "        scaler.load_state_dict(start_checkpoint['scaler_state_dict'])\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        best_acc = 0\n",
    "        best_prec = 0\n",
    "        best_rec = 0\n",
    "        \n",
    "    log_freq = (epochs - start_epoch) // 1 # how often to print stats when no progress is made\n",
    "    \n",
    "    for epoch in tqdm(range(start_epoch, epochs), desc=\"Epochs\"):\n",
    "        counter += 1\n",
    "        train_loss, train_acc, train_prec, train_rec = train_step(\n",
    "            model,\n",
    "            train_dl,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            loss_fn,\n",
    "            scaler,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        valid_loss, valid_acc, valid_prec, valid_rec = valid_step(\n",
    "            model,\n",
    "            valid_dl,\n",
    "            loss_fn,\n",
    "            device\n",
    "        )\n",
    "\n",
    "        progress = False\n",
    "        \n",
    "        if valid_acc > best_acc:\n",
    "            progress = True\n",
    "            best_acc = valid_acc\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_accuracy.pth')\n",
    "\n",
    "        if valid_prec > best_prec:\n",
    "            progress = True\n",
    "            best_prec = valid_prec\n",
    "            ccheckpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_precision.pth')\n",
    "\n",
    "        if valid_rec < best_rec:\n",
    "            progress = True\n",
    "            best_rec = valid_rec\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/best_recall.pth')\n",
    "\n",
    "        if epoch == epochs-1:\n",
    "            checkpoint = {\n",
    "                'epoch': epoch,\n",
    "                'best_acc': best_acc,\n",
    "                'best_prec': best_prec,\n",
    "                'best_rec': best_rec,\n",
    "                'model_state_dict':  model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'scaler_state_dict': scaler.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, f'../tmp_model_checkpoints/last.pth')\n",
    "            \n",
    "        if True or progress or counter >= log_freq:\n",
    "            counter = 0\n",
    "            print(\n",
    "                f\"Epoch: {epoch+1} | \"\n",
    "                f\"[train] loss: {train_loss:.4f} | \"\n",
    "                f\"[valid] loss: {valid_loss:.4f} | \"\n",
    "                f\"[valid] Accuracy: {valid_acc:.4f} | \"\n",
    "                f\"[valid] Precision: {valid_prec:.4f} | \"\n",
    "                f\"[valid] Recall: {valid_rec:.4f}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dbe29c3-3879-4169-8db1-732dd406316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(\"train/images/\")\n",
    "paths = [os.path.join(\"train/images/\", filename) for filename in files if filename.lower().endswith(\".jpg\")]\n",
    "random.shuffle(paths)\n",
    "split_idx = int(0.8 * len(paths))\n",
    "train_paths = paths[:split_idx]\n",
    "valid_paths = paths[split_idx:]\n",
    "\n",
    "files = os.listdir(\"test/images/\")\n",
    "test_paths = [os.path.join(\"test/images/\", filename) for filename in files if filename.lower().endswith(\".jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7292c6f6-8fe3-45a0-b722-c851e34fbae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8827827abe6647189568cd823f883212",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7682 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1692ddb0136745e69f286ecf1d9bddc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1921 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5065e82c965c4ff991fbdc0fccf1c5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1695 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ds = CrackDataset(train_paths)\n",
    "valid_ds = CrackDataset(valid_paths)\n",
    "test_ds = CrackDataset(test_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e004c07f-7e9d-473b-b530-42dea13569c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3aef71a2eb46819b85dedd71b52e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | [train] loss: 0.0582 | [valid] loss: 0.0083 | [valid] Accuracy: 15.8678 | [valid] Precision: 1.0000 | [valid] Recall: 0.9995\n",
      "Epoch: 2 | [train] loss: 0.0737 | [valid] loss: 0.4550 | [valid] Accuracy: 14.6942 | [valid] Precision: 0.9917 | [valid] Recall: 0.9184\n",
      "Epoch: 3 | [train] loss: 0.1135 | [valid] loss: 0.0002 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n",
      "Epoch: 4 | [train] loss: 0.0110 | [valid] loss: 0.0001 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n",
      "Epoch: 5 | [train] loss: 0.0071 | [valid] loss: 0.0000 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n",
      "Epoch: 6 | [train] loss: 0.0154 | [valid] loss: 0.0000 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n",
      "Epoch: 7 | [train] loss: 0.0002 | [valid] loss: 0.0000 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n",
      "Epoch: 8 | [train] loss: 0.0039 | [valid] loss: 0.0026 | [valid] Accuracy: 15.8678 | [valid] Precision: 1.0000 | [valid] Recall: 0.9995\n",
      "Epoch: 9 | [train] loss: 0.0033 | [valid] loss: 0.0000 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n",
      "Epoch: 10 | [train] loss: 0.0005 | [valid] loss: 0.0000 | [valid] Accuracy: 15.8760 | [valid] Precision: 1.0000 | [valid] Recall: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_dl = DataLoader(train_ds, batch_size=16, shuffle=True, num_workers=os.cpu_count()-1)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=16, shuffle=False, num_workers=os.cpu_count()-1)\n",
    "\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = OneCycleLR(optimizer, max_lr=0.1, steps_per_epoch=len(train_dl), epochs=10)\n",
    "\n",
    "train(model, train_dl, valid_dl, optimizer, scheduler, loss_fn, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004ce07c-31b1-4475-a3cb-23be5acdc6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_General",
   "language": "python",
   "name": "python_general"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
